{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "from googletrans import Translator, constants\n",
    "from pprint import pprint\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from playsound import playsound\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import *\n",
    "import arabic_reshaper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the vedio and convert it into audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation(pathv):\n",
    "    clip = mp.VideoFileClip(pathv)\n",
    "    patha = pathv[0:pathv.find(\".\")]+\".wav\"\n",
    "    clip.audio.write_audiofile(patha)\n",
    "    return patha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the audio file into smaller shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SiplttingAudio(PathA,time):\n",
    "    ListOfPathAudio = []\n",
    "    time = time * 1000\n",
    "    print(PathA)\n",
    "    newAudio = AudioSegment.from_wav(PathA)\n",
    "    x = newAudio.duration_seconds * 1000 \n",
    "    count = 0\n",
    "    PathA = PathA[0:PathA.find(\".wav\")]\n",
    "    while(x>count):\n",
    "        t1 =  count\n",
    "        t2 =  time + count\n",
    "        newAudio1 = newAudio[t1:t2]\n",
    "        newAudio1.export(PathA+str(int(count/1000))+'.wav', format=\"wav\")\n",
    "        ListOfPathAudio.append(PathA+str(int(count/1000))+'.wav')\n",
    "        count = t2\n",
    "    return ListOfPathAudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the text from the audioes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpeechToText(ListOfPathAudio):\n",
    "    ListText = []\n",
    "    r = sr.Recognizer()\n",
    "    for audio in ListOfPathAudio:\n",
    "        with sr.AudioFile(audio) as source:\n",
    "            audio_data = r.record(source)\n",
    "            text = r.recognize_google(audio_data)\n",
    "            ListText.append(text)\n",
    "    return ListText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate the text into another language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transliation(ListText,lang):\n",
    "    ListOfText = []\n",
    "    translator = Translator()\n",
    "    for sent in ListText:\n",
    "        translations = translator.translate(sent, dest=lang)\n",
    "        ListOfText.append(translations.text)\n",
    "    return ListOfText\n",
    "#     for translation in translations:\n",
    "#         print(f\"{translation.origin} ({translation.src}) --> {translation.text} ({translation.dest})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the tranzlated text into the video again as a subtitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddTextToVideo(pathv,ListOfText,ListText):\n",
    "    clip = VideoFileClip(pathv)\n",
    "    time = clip.duration\n",
    "    du = time/len(ListOfText)\n",
    "    clip = clip.volumex(0.5)\n",
    "    listy = []\n",
    "    listy.append(clip)\n",
    "    count = 0\n",
    "    tcount = time\n",
    "    n1 = 0\n",
    "    for n in ListOfText:\n",
    "        if(tcount>0):\n",
    "            txt_clip = TextClip(str(n+\"\\n\"+ListText[n1]), fontsize = 25, color = 'red')\n",
    "            txt_clip = txt_clip.set_pos('bottom').set_start(count).set_duration(du)\n",
    "            listy.append(txt_clip)\n",
    "            count+=du\n",
    "            tcount-=du\n",
    "            n1 = n1 + 1\n",
    "        else:\n",
    "            break\n",
    "    video = CompositeVideoClip(listy)\n",
    "    video.ipython_display(width = 280,maxduration = int(time*2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(pathv):\n",
    "    PathAudio = translation(pathv)\n",
    "    ListOfPathAudio = SiplttingAudio(PathAudio,5)\n",
    "    ListText = SpeechToText(ListOfPathAudio[100:200])\n",
    "    return ListText\n",
    "#     ListOfText = Transliation(ListText,'fr')\n",
    "#     AddTextToVideo(pathv,ListOfText,ListText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ListText = main(\"E:\\\\Graduation Project\\\\New folder\\\\stereo_file.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
